{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<center>===========================================================================================================</center>**\n",
    "**<center>All Necessary Imports</center>**\n",
    "**<center>===========================================================================================================</center>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of CPU cores: 32\n",
      "CPU utilization per core: [79.7, 36.8, 77.9, 32.9, 78.3, 28.6, 75.4, 63.4, 80.0, 27.5, 77.1, 27.5, 81.4, 30.0, 95.7, 28.6, 54.3, 52.2, 52.2, 52.2, 52.2, 50.0, 51.5, 52.9, 52.2, 50.0, 50.7, 52.9, 51.4, 52.2, 50.7, 52.2]\n",
      "Number of free CPU cores: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import psutil\n",
    "import pickle\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Lock\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, \n",
    "    AdaBoostClassifier, \n",
    "    GradientBoostingClassifier, \n",
    "    ExtraTreesClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,  \n",
    "    precision_recall_curve, \n",
    "    roc_auc_score, \n",
    "    roc_curve,\n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score, \n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Get the number of logical cores\n",
    "num_cores = psutil.cpu_count(logical=True)\n",
    "print(f\"Total number of CPU cores: {num_cores}\")\n",
    "\n",
    "# Get the percentage utilization of each core\n",
    "cpu_percent_per_core = psutil.cpu_percent(percpu=True)\n",
    "print(f\"CPU utilization per core: {cpu_percent_per_core}\")\n",
    "\n",
    "# Calculate the number of free cores (assuming a core is free if its utilization is less than a threshold, e.g., 10%)\n",
    "threshold = 10.0\n",
    "free_cores = sum(1 for percent in cpu_percent_per_core if percent < threshold)\n",
    "print(f\"Number of free CPU cores: {free_cores}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<center>===========================================================================================================</center>**\n",
    "**<center>Load the Data</center>**\n",
    "**<center>===========================================================================================================</center>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_df = pd.read_csv('data/processed/selected_features.csv')\n",
    "\n",
    "features = selected_features_df.drop(columns=['target'])\n",
    "target = selected_features_df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<center>===========================================================================================================</center>**\n",
    "**<center>Model Performance Evaluation</center>**\n",
    "**<center>===========================================================================================================</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Necessary functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test):\n",
    "    X_train_copy = X_train.copy()\n",
    "    y_train_copy = y_train.copy()\n",
    "    X_test_copy = X_test.copy()\n",
    "    y_test_copy = y_test.copy()\n",
    "\n",
    "    model.fit(X_train_copy, y_train_copy)\n",
    "    train_predictions = model.predict(X_train_copy)\n",
    "    test_predictions = model.predict(X_test_copy)\n",
    "    \n",
    "    train_accuracy = accuracy_score(y_train_copy, train_predictions)\n",
    "    test_accuracy = accuracy_score(y_test_copy, test_predictions)\n",
    "    \n",
    "    test_precision = precision_score(y_test_copy, test_predictions)\n",
    "    test_recall = recall_score(y_test_copy, test_predictions)\n",
    "    test_f1 = f1_score(y_test_copy, test_predictions)\n",
    "    test_auc = roc_auc_score(y_test_copy, model.predict_proba(X_test_copy)[:, 1])\n",
    "    test_conf_matrix = confusion_matrix(y_test_copy, test_predictions)\n",
    "    \n",
    "    # Calculate FPR, TPR, precision, recall\n",
    "    fpr, tpr, _ = roc_curve(y_test_copy, model.predict_proba(X_test_copy)[:, 1])\n",
    "    precision, recall, _ = precision_recall_curve(y_test_copy, model.predict_proba(X_test_copy)[:, 1])\n",
    "    \n",
    "    results = {\n",
    "        'name': name,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_precision': test_precision,\n",
    "        'test_recall': test_recall,\n",
    "        'test_f1': test_f1,\n",
    "        'test_auc': test_auc,\n",
    "        'test_confusion_matrix': test_conf_matrix,\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "    return results\n",
    "\n",
    "\n",
    "def results_to_df(results):\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_roc_curves(results, df_results):\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    for result in results:\n",
    "        name = result['name']\n",
    "        fpr = np.array(result['fpr'])\n",
    "        tpr = np.array(result['tpr'])\n",
    "        plt.plot(fpr, tpr, label=f\"{name} (AUC = {result['test_auc']:.2f})\")\n",
    "        print(f\"Best parameters for {name}: {result['best_params']}\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    print(df_results)\n",
    "\n",
    "\n",
    "checkpoint_file = 'grid_search_checkpoint.pkl'\n",
    "lock = Lock()\n",
    "\n",
    "# Load checkpoint if exists\n",
    "if os.path.exists(checkpoint_file):\n",
    "    with open(checkpoint_file, 'rb') as f:\n",
    "        checkpoint = pickle.load(f)\n",
    "else:\n",
    "    checkpoint = {'completed': [], 'results': []}\n",
    "    \n",
    "# Function to perform grid search and evaluate model\n",
    "def grid_search_evaluate_model(name, model, param_grid, X_train, y_train, X_test, y_test, lock):\n",
    "    X_train_copy = X_train.copy()\n",
    "    y_train_copy = y_train.copy()\n",
    "    X_test_copy = X_test.copy()\n",
    "    y_test_copy = y_test.copy()\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    grid_search.fit(X_train_copy, y_train_copy)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    result = evaluate_model(name, best_model, X_train_copy, y_train_copy, X_test_copy, y_test_copy)\n",
    "    result['best_params'] = grid_search.best_params_\n",
    "    \n",
    "    # Using the lock to ensure only one process writes to the checkpoint file at a time\n",
    "    with lock:\n",
    "        checkpoint['results'].append(result)\n",
    "        checkpoint['completed'].append(name)\n",
    "\n",
    "        with open(checkpoint_file, 'wb') as f:\n",
    "            pickle.dump(checkpoint, f)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Train-Test Split__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the RFE-applied data into training and testing sets (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Model Training with Grid Search__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Parameter search space\n",
    "param_grids = {\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'max_depth': [3, 7, 10],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0],\n",
    "        'gamma': [0, 0.2],\n",
    "        'reg_alpha': [0, 1],\n",
    "        'reg_lambda': [1, 10],\n",
    "        'scale_pos_weight': [1, 10]\n",
    "    },\n",
    "    'AdaBoost': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.1, 0.5, 1],\n",
    "        'algorithm': ['SAMME.R']\n",
    "    },\n",
    "    'NaiveBayes': {\n",
    "        'var_smoothing': np.logspace(-9, -1, 20)\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None, 10, 30],\n",
    "        'min_samples_split': [2, 10],\n",
    "        'min_samples_leaf': [1, 5],\n",
    "        'max_features': [None, 'sqrt'],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None, 10, 30],\n",
    "        'min_samples_split': [2, 10],\n",
    "        'min_samples_leaf': [1, 5],\n",
    "        'max_features': ['sqrt', 'log2'],\n",
    "        'bootstrap': [True],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'penalty': ['l2'],\n",
    "        'C': np.logspace(-4, 4, 10),\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'max_iter': [200],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 7],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'min_samples_split': [2, 10],\n",
    "        'min_samples_leaf': [1, 5]\n",
    "    },\n",
    "    'KNN': {\n",
    "        'n_neighbors': [3, 5, 7],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'p': [1, 2]\n",
    "    },\n",
    "    'Extra Trees': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None, 10, 30],\n",
    "        'min_samples_split': [2, 10],\n",
    "        'min_samples_leaf': [1, 5],\n",
    "        'max_features': ['sqrt', 'log2'],\n",
    "        'bootstrap': [True]\n",
    "    }\n",
    "}\n",
    "\n",
    "models = {\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss'),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'NaiveBayes': GaussianNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'SVM': SVC(probability=True),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Extra Trees': ExtraTreesClassifier(),\n",
    "}\n",
    "\n",
    "# Perform parallel grid search and evaluation\n",
    "results = Parallel(n_jobs=-1, backend='loky')(\n",
    "    delayed(grid_search_evaluate_model)(name, model, param_grids[name], X_train, y_train, X_test, y_test)\n",
    "    for name, model in models.items()\n",
    ")\n",
    "\n",
    "df_results = results_to_df(results)\n",
    "\n",
    "plot_roc_curves(results, df_results)\n",
    "\n",
    "df_results = df_results.drop(columns=['fpr', 'tpr', 'precision', 'recall'])\n",
    "\n",
    "print(df_results)\n",
    "\n",
    "for result in results:\n",
    "    name = result['name']\n",
    "\n",
    "    print(f\"Best parameters for {name}: {result['best_params']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
